{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c124118c-ed63-4e32-b29a-2f8f8394b35d",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26f50599-fcb5-4727-aac0-f5fd9d92ed5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\semde\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] Kan opgegeven procedure niet vinden'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import os, re, math\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from transformers import pipeline, AutoTokenizer\n",
    "import unicodedata\n",
    "from IPython.display import display, HTML\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd6375c-d3ad-45d2-914a-d825030873b5",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e94fd5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Config: RobBERT v2 + neutral band en gewichten (titel/lead/body) ===\n",
    "ROB_BERT_SENTIMENT = \"DTAI-KULeuven/robbert-v2-dutch-sentiment\"\n",
    "\n",
    "DATA_DIR = \"data\"\n",
    "OUT_CSV  = \"out/sentiment_results.csv\"\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Weights:\n",
    "    title: float = 1.0\n",
    "    lead:  float = 1.0\n",
    "    body:  float = 1.0   # body weer meewegen\n",
    "\n",
    "WEIGHTS = Weights()\n",
    "\n",
    "# Neutral band voor beslissing op basis van signed score (p_pos - p_neg)\n",
    "NEUTRAL_BAND = 0\n",
    "\n",
    "# Chunk-instellingen (gebruik je al elders)\n",
    "MAX_TOKENS = 400\n",
    "STRIDE     = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6099e5-28bd-400d-9d31-bd75fc876724",
   "metadata": {},
   "source": [
    "# Load Title, Lead and Body Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f202cda9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id                                              title  \\\n",
      "0   7  Nederlandse patiënt wacht te lang op betere me...   \n",
      "1  10  Nieuwe kankermedicijnen leveren meer financiël...   \n",
      "2  11         Hoe controleer je verstopte moedervlekken?   \n",
      "3  16  'Ik vind het erg als 'n infuus van 25.000 euro...   \n",
      "4  21  Wachtlijsten en personeelstekort: het 'zorginf...   \n",
      "\n",
      "                                                lead  \\\n",
      "0  Wat een prachtig bericht onlangs, dat meer kan...   \n",
      "1  Vorige week verscheen in Trouw een artikel met...   \n",
      "2  Meer dan twintig jaar geleden ontdekte ze op h...   \n",
      "3  Waarom schrijven artsen 1005 milligram van een...   \n",
      "4  De gezondheidszorg is 'op', er zit geen rek me...   \n",
      "\n",
      "                                                body              bron  \n",
      "0  Maar het is jammer dat het zo lang duurt voord...             Trouw  \n",
      "1  Nederland is een mooi land waarin uiteindelijk...     de Volkskrant  \n",
      "2  Eerst over die dagelijkse inspectie. Dat is ec...             Trouw  \n",
      "3  Ziekenhuisapotheker Roelof van Leeuwen zet zic...  AD De Dordtenaar  \n",
      "4  Verpleegkundigen, verzorgenden, huisartsen, sp...               NRC  \n",
      "Aantal rijen ingelezen: 70\n"
     ]
    }
   ],
   "source": [
    "# === Nieuw: inlezen uit Title_Lead_Body.xlsx ===\n",
    "# Pad aanpassen indien nodig; nu staat hij naast het notebook.\n",
    "XLSX_PATH = \"out/Title_Lead_Body.xlsx\"\n",
    "\n",
    "df_input = pd.read_excel(XLSX_PATH)\n",
    "\n",
    "# Zorg dat de kolommen precies 'id', 'title', 'lead', 'body' heten\n",
    "expected = {\"id\",\"title\",\"lead\",\"body\"}\n",
    "missing = expected - set(df_input.columns.str.lower())\n",
    "if missing:\n",
    "    raise ValueError(f\"Ontbrekende kolommen in {XLSX_PATH}: {missing}. \"\n",
    "                     \"Zorg voor kolommen: id, title, lead, body.\")\n",
    "\n",
    "# Normaliseer kolomnamen en vul lege waarden op\n",
    "df_input = df_input.rename(columns={c: c.lower() for c in df_input.columns})\n",
    "df_input[[\"title\",\"lead\",\"body\"]] = df_input[[\"title\",\"lead\",\"body\"]].fillna(\"\")\n",
    "print(df_input.head())\n",
    "print(f\"Aantal rijen ingelezen: {len(df_input)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f38ae65-2dee-4ace-9f4a-27e103f28eb6",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da6aa4cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\semde\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# === Alleen de RobBERT v2 sentiment pipeline laden ===\n",
    "ROB_NAME = \"DTAI-KULeuven/robbert-v2-dutch-sentiment\"\n",
    "\n",
    "def load_pipe(name, tries=2):\n",
    "    last = None\n",
    "    for i in range(tries):\n",
    "        try:\n",
    "            clf = pipeline(\n",
    "                task=\"sentiment-analysis\",\n",
    "                model=name,\n",
    "                tokenizer=name,\n",
    "                top_k=None,          # return_all_scores vervangen\n",
    "                truncation=True\n",
    "            )\n",
    "            return clf\n",
    "        except Exception as e:\n",
    "            last = e\n",
    "    raise last\n",
    "\n",
    "rob_pipe = load_pipe(ROB_NAME)\n",
    "TOKENIZER = AutoTokenizer.from_pretrained(ROB_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622d7ba6-fbea-48ce-8a10-27b7d7ca8b47",
   "metadata": {},
   "source": [
    "# Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a58e760e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_chunks_by_tokens(text: str, tokenizer, max_tokens: int = 400, stride: int = 50) -> List[str]:\n",
    "    if not text.strip():\n",
    "        return []\n",
    "    toks = tokenizer.encode(text, add_special_tokens=False)\n",
    "    chunks = []\n",
    "    i = 0\n",
    "    while i < len(toks):\n",
    "        window = toks[i:i+max_tokens]\n",
    "        if not window:\n",
    "            break\n",
    "        chunk = tokenizer.decode(window, skip_special_tokens=True)\n",
    "        chunks.append(chunk)\n",
    "        if i + max_tokens >= len(toks):\n",
    "            break\n",
    "        i += max_tokens - stride\n",
    "    return chunks\n",
    "\n",
    "def chunk_body(text: str, tokenizer, prefer_paragraphs: bool = True, max_tokens: int = 300, stride: int = 50) -> List[str]:\n",
    "    if not text.strip():\n",
    "        return []\n",
    "    if prefer_paragraphs:\n",
    "        paras = re.split(r\"\\\\n\\\\s*\\\\n\", text.strip())\n",
    "        paras = [p.strip() for p in paras if p.strip()]\n",
    "        chunks = []\n",
    "        for p in paras:\n",
    "            if len(tokenizer.encode(p, add_special_tokens=False)) <= max_tokens:\n",
    "                chunks.append(p)\n",
    "            else:\n",
    "                chunks.extend(make_chunks_by_tokens(p, tokenizer, max_tokens=max_tokens, stride=stride))\n",
    "        return chunks\n",
    "    else:\n",
    "        return make_chunks_by_tokens(text, tokenizer, max_tokens=max_tokens, stride=stride)\n",
    "\n",
    "\n",
    "LABEL_MAP = {\n",
    "    \"POSITIVE\": \"positief\", \"NEGATIVE\": \"negatief\", \"NEUTRAL\": \"neutraal\",\n",
    "    \"Positive\": \"positief\", \"Negative\": \"negatief\", \"Neutral\": \"neutraal\",\n",
    "    \"positief\": \"positief\", \"negatief\": \"negatief\", \"neutraal\": \"neutraal\"\n",
    "}\n",
    "\n",
    "def normalize_pnn(probs: dict) -> dict:\n",
    "    import numpy as np\n",
    "    arr = np.array([\n",
    "        probs.get(\"positief\", 0.0),\n",
    "        probs.get(\"negatief\", 0.0),\n",
    "        probs.get(\"neutraal\", 0.0)\n",
    "    ], dtype=float)\n",
    "    s = arr.sum()\n",
    "    if s <= 0:\n",
    "        return {\"positief\":0.0, \"negatief\":0.0, \"neutraal\":1.0}\n",
    "    arr = arr / s\n",
    "    return {\"positief\": float(arr[0]), \"negatief\": float(arr[1]), \"neutraal\": float(arr[2])}\n",
    "\n",
    "def score_text_with_pipe(text: str, clf) -> dict:\n",
    "    text = (text or \"\").strip()\n",
    "    if not text:\n",
    "        return {\"positief\":0.0, \"negatief\":0.0, \"neutraal\":1.0}\n",
    "    out = clf(text, truncation=True)\n",
    "    scores = out[0]  # top_k=None -> lijst van dicts\n",
    "    probs = {\"positief\":0.0, \"negatief\":0.0, \"neutraal\":0.0}\n",
    "    for item in scores:\n",
    "        lab = LABEL_MAP.get(item[\"label\"])\n",
    "        if lab:\n",
    "            probs[lab] = float(item[\"score\"])\n",
    "    return normalize_pnn(probs)\n",
    "\n",
    "MAX_MODEL_TOKENS = 400\n",
    "HEADROOM = 8\n",
    "SAFE_MAX = MAX_MODEL_TOKENS - HEADROOM\n",
    "\n",
    "def token_chunks(text, tokenizer, max_tokens=SAFE_MAX, stride=50):\n",
    "    if not text or not text.strip():\n",
    "        return []\n",
    "    ids = tokenizer.encode(text, add_special_tokens=False)\n",
    "    if len(ids) <= max_tokens:\n",
    "        return [text]\n",
    "    out, i = [], 0\n",
    "    while i < len(ids):\n",
    "        j = min(i + max_tokens, len(ids))\n",
    "        chunk_ids = ids[i:j]\n",
    "        out.append(tokenizer.decode(chunk_ids, clean_up_tokenization_spaces=True))\n",
    "        if j >= len(ids): break\n",
    "        i = max(j - stride, i + 1)\n",
    "    return out\n",
    "\n",
    "def aggregate_article_with_pipe_binary(title, lead, body_chunks, clf, tokenizer,\n",
    "                                       weights=None):\n",
    "    \"\"\"\n",
    "    Alleen POS/NEG. Negeert neutraal volledig.\n",
    "    - Titel/lead/body worden gechunked zoals voorheen.\n",
    "    - Weeg t/l/b via weights (default title=2.0, lead=1.0, body=1.0).\n",
    "    - Label = 'positief' als p_pos >= p_neg, anders 'negatief'.\n",
    "    \"\"\"\n",
    "    if weights is None:\n",
    "        from dataclasses import dataclass\n",
    "        @dataclass\n",
    "        class W: title: float = 1.0; lead: float = 1.0; body: float = 1.0\n",
    "        weights = W()\n",
    "\n",
    "    parts = []\n",
    "\n",
    "    # Titel\n",
    "    t_chunks = token_chunks(title or \"\", tokenizer, max_tokens=SAFE_MAX, stride=50)\n",
    "    w_t_each = (weights.title / max(len(t_chunks), 1)) if t_chunks else 0.0\n",
    "    for t in t_chunks:\n",
    "        if t.strip():\n",
    "            parts.append((t.strip(), w_t_each))\n",
    "\n",
    "    # Lead\n",
    "    l_chunks = token_chunks(lead or \"\", tokenizer, max_tokens=SAFE_MAX, stride=50)\n",
    "    w_l_each = (weights.lead / max(len(l_chunks), 1)) if l_chunks else 0.0\n",
    "    for l in l_chunks:\n",
    "        if l.strip():\n",
    "            parts.append((l.strip(), w_l_each))\n",
    "\n",
    "    # Body (al gechunked upstream)\n",
    "    if body_chunks:\n",
    "        w_b_each = weights.body / len(body_chunks)\n",
    "        for ch in body_chunks:\n",
    "            ch = (ch or \"\").strip()\n",
    "            if ch:\n",
    "                parts.append((ch, w_b_each))\n",
    "\n",
    "    if not parts:\n",
    "        # lege tekst -> kies 'negatief' conservatief of geef pos=neg=0.5\n",
    "        return {\"p_pos\":0.5, \"p_neg\":0.5, \"label\":\"negatief\"}\n",
    "\n",
    "    acc_pos = 0.0\n",
    "    acc_neg = 0.0\n",
    "    total_w = 0.0\n",
    "\n",
    "    for txt, w in parts:\n",
    "        out = clf(txt, truncation=True, max_length=MAX_MODEL_TOKENS, padding=False)\n",
    "        scores = out[0]  # lijst met dicts\n",
    "        p_pos = p_neg = 0.0\n",
    "        for item in scores:\n",
    "            lab = LABEL_MAP.get(item[\"label\"])\n",
    "            if lab == \"positief\":\n",
    "                p_pos = float(item[\"score\"])\n",
    "            elif lab == \"negatief\":\n",
    "                p_neg = float(item[\"score\"])\n",
    "            # 'neutraal' negeren we bewust\n",
    "\n",
    "        # Her-normaliseer over POS/NEG alleen (optioneel, maar aan te raden)\n",
    "        s = p_pos + p_neg\n",
    "        if s > 0:\n",
    "            p_pos2 = p_pos / s\n",
    "            p_neg2 = p_neg / s\n",
    "        else:\n",
    "            # als model iets geks geeft, maak gelijk verdeeld\n",
    "            p_pos2 = p_neg2 = 0.5\n",
    "\n",
    "        acc_pos += p_pos2 * w\n",
    "        acc_neg += p_neg2 * w\n",
    "        total_w += w\n",
    "\n",
    "    if total_w <= 0:\n",
    "        total_w = 1.0\n",
    "    p_pos_bin = acc_pos / total_w\n",
    "    p_neg_bin = acc_neg / total_w\n",
    "\n",
    "    label = \"positief\" if p_pos_bin >= p_neg_bin else \"negatief\"\n",
    "    return {\"p_pos\": float(p_pos_bin), \"p_neg\": float(p_neg_bin), \"label\": label}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed84f3d-ba7e-4aea-97dc-23bef9861a26",
   "metadata": {},
   "source": [
    "# NLP Classification Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "44dbc295",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 70/70 [01:59<00:00,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id                                              title  \\\n",
      "0   7  Nederlandse patiënt wacht te lang op betere me...   \n",
      "1  10  Nieuwe kankermedicijnen leveren meer financiël...   \n",
      "2  11         Hoe controleer je verstopte moedervlekken?   \n",
      "3  16  'Ik vind het erg als 'n infuus van 25.000 euro...   \n",
      "4  21  Wachtlijsten en personeelstekort: het 'zorginf...   \n",
      "\n",
      "                                                lead  rob_p_pos  rob_p_neg  \\\n",
      "0  Wat een prachtig bericht onlangs, dat meer kan...   0.411551   0.588449   \n",
      "1  Vorige week verscheen in Trouw een artikel met...   0.391569   0.608431   \n",
      "2  Meer dan twintig jaar geleden ontdekte ze op h...   0.693425   0.306575   \n",
      "3  Waarom schrijven artsen 1005 milligram van een...   0.338410   0.661590   \n",
      "4  De gezondheidszorg is 'op', er zit geen rek me...   0.494780   0.505220   \n",
      "\n",
      "  rob_label  \n",
      "0  negatief  \n",
      "1  negatief  \n",
      "2  positief  \n",
      "3  negatief  \n",
      "4  negatief  \n",
      "Klaar. 70 rijen geclassificeerd.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "for _, r in tqdm(df_input.iterrows(), total=len(df_input)):\n",
    "    art_id = r[\"id\"]\n",
    "    title  = r[\"title\"] or \"\"\n",
    "    lead   = r[\"lead\"]  or \"\"\n",
    "    body   = r[\"body\"]  or \"\"\n",
    "\n",
    "    # Body chunken zoals voorheen\n",
    "    body_chunks = chunk_body(\n",
    "        body,\n",
    "        TOKENIZER,\n",
    "        prefer_paragraphs=True,\n",
    "        max_tokens=MAX_TOKENS,\n",
    "        stride=STRIDE\n",
    "    )\n",
    "\n",
    "    # Binaire aggregatie (past bij je bestaande pipeline)\n",
    "    rob_bin = aggregate_article_with_pipe_binary(\n",
    "        title, lead, body_chunks,\n",
    "        rob_pipe, TOKENIZER\n",
    "    )\n",
    "\n",
    "    rows.append({\n",
    "        \"id\": art_id,\n",
    "        \"title\": title,\n",
    "        \"lead\": lead,\n",
    "        \"rob_p_pos\": rob_bin[\"p_pos\"],\n",
    "        \"rob_p_neg\": rob_bin[\"p_neg\"],\n",
    "        \"rob_label\": rob_bin[\"label\"],  # 'positief' of 'negatief'\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "print(df.head())\n",
    "print(f\"Klaar. {len(df)} rijen geclassificeerd.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "54bfa0aa-81b3-41b1-9644-ff6947c5bbcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DONE] Geschreven naar out/sentiment_results.csv\n"
     ]
    }
   ],
   "source": [
    "df.to_csv(\"out/sentiment_results.csv\", index=False, encoding=\"utf-8\")\n",
    "print(\"[DONE] Geschreven naar out/sentiment_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59905cef-9bb6-4aad-beaa-3096691bd2dd",
   "metadata": {},
   "source": [
    "# Classification Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ed9e99f9-943f-4699-88b8-f8ec5da36dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  robbert_negatief  robbert_positief\n",
      "0   7              True             False\n",
      "1  10              True             False\n",
      "2  11             False              True\n",
      "3  16              True             False\n",
      "4  21              True             False\n"
     ]
    }
   ],
   "source": [
    "# === Load results (RobBERT only) ===\n",
    "\n",
    "# 1) Resultaten ophalen\n",
    "#    - bij voorkeur de in-memory 'df' uit je classificatieloop\n",
    "#    - anders uit de CSV (legacy)\n",
    "df_results = pd.read_csv(\"out/sentiment_results.csv\")\n",
    "\n",
    "# 2) Zorg voor een nette 'id' kolom (int)\n",
    "def to_int_id(v):\n",
    "    try:\n",
    "        return int(v)\n",
    "    except Exception:\n",
    "        return pd.NA\n",
    "\n",
    "if 'id' not in df_results.columns:\n",
    "    if 'file' in df_results.columns:\n",
    "        import re\n",
    "        def extract_id_legacy(val):\n",
    "            s = str(val)\n",
    "            m = re.search(r'bericht[_\\s-]*(\\d+)', s, flags=re.I)\n",
    "            if m: return int(m.group(1))\n",
    "            m2 = re.search(r'(\\d+)', s)\n",
    "            return int(m2.group(1)) if m2 else pd.NA\n",
    "        df_results['id'] = df_results['file'].apply(extract_id_legacy)\n",
    "    else:\n",
    "        df_results['id'] = np.arange(1, len(df_results) + 1)\n",
    "\n",
    "df_results['id'] = df_results['id'].apply(to_int_id)\n",
    "\n",
    "# 3) rob_label normaliseren\n",
    "if 'rob_label' not in df_results.columns:\n",
    "    raise KeyError(\"Column 'rob_label' ontbreekt in de resultaten.\")\n",
    "df_results['rob_label'] = (\n",
    "    df_results['rob_label'].astype(str).str.strip().str.lower()\n",
    ")\n",
    "\n",
    "df_labels = df_results[['id', 'rob_label']].copy()\n",
    "\n",
    "# 4) One-hot encoding met alleen aanwezige klassen\n",
    "present_classes = sorted(df_labels['rob_label'].dropna().unique().tolist())\n",
    "df_encoded = pd.get_dummies(df_labels, columns=['rob_label'], prefix='robbert')\n",
    "\n",
    "print(df_encoded.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c721f36c-0e73-4002-84ca-5c44c22d02ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     id  robbert_negatief  robbert_positief\n",
      "65  271              True             False\n",
      "66  287             False              True\n",
      "67  296             False              True\n",
      "68  300             False              True\n",
      "69  306             False              True\n"
     ]
    }
   ],
   "source": [
    "print(df_encoded.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b13baf7e-c8be-48b8-b3d3-525f660a34fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         positief  negatief\n",
      "Model                      \n",
      "robbert        51        19\n"
     ]
    }
   ],
   "source": [
    "# 5) Samenvatting (positief/negatief/neutraal als aanwezig)\n",
    "summary = {}\n",
    "for cls in ['positief', 'negatief', 'neutraal']:\n",
    "    col = f'robbert_{cls}'\n",
    "    if col in df_encoded.columns:\n",
    "        summary[cls] = int(df_encoded[col].sum())\n",
    "\n",
    "summary_df = pd.DataFrame([summary], index=['robbert']).fillna(0).astype(int)\n",
    "summary_df.index.name = \"Model\"\n",
    "print(summary_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bbfb9f-bdec-41ac-9baa-f0fd14caf124",
   "metadata": {},
   "source": [
    "# Analyse tov human sentiment (maaike)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cae47f8e-d53d-46f7-868e-2eb9ced9ceea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RobBERT (binaire evaluatie) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positief      0.745     0.875     0.805        40\n",
      "    negatief      0.722     0.520     0.605        25\n",
      "\n",
      "    accuracy                          0.738        65\n",
      "   macro avg      0.733     0.698     0.705        65\n",
      "weighted avg      0.736     0.738     0.728        65\n",
      "\n",
      "Confusion matrix:\n",
      "               Pred positief  Pred negatief\n",
      "True positief             35              5\n",
      "True negatief             12             13\n"
     ]
    }
   ],
   "source": [
    "# === Evaluatie: Human vs RobBERT (binaire evaluatie: positief vs negatief) ===\n",
    "\n",
    "# 1) Resultaten ophalen (in-memory 'df' heeft de voorkeur)\n",
    "try:\n",
    "    df_results = df.copy()\n",
    "except NameError:\n",
    "    df_results = pd.read_csv(\"out/sentiment_results.csv\")\n",
    "\n",
    "# 2) Human labels inladen\n",
    "df_h = pd.read_excel(\"out/Human_Sentiment.xlsx\")  # verwacht: Artikel, Sentiment\n",
    "\n",
    "# 3) IDs netjes naar int (of None)\n",
    "def to_int_or_none(x):\n",
    "    try:\n",
    "        return int(x)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "if 'id' not in df_results.columns:\n",
    "    raise KeyError(\"Resultaten missen een 'id' kolom.\")\n",
    "df_results['id'] = df_results['id'].apply(to_int_or_none)\n",
    "\n",
    "if not pd.api.types.is_integer_dtype(df_h['Artikel']):\n",
    "    df_h['Artikel'] = df_h['Artikel'].apply(to_int_or_none)\n",
    "\n",
    "# 4) Labels normaliseren\n",
    "df_h['Human_Label'] = df_h['Sentiment'].astype(str).str.strip().str.lower()\n",
    "# alleen binaire klassen\n",
    "df_h = df_h[df_h['Human_Label'].isin({'positief','negatief'})].copy()\n",
    "\n",
    "if 'rob_label' not in df_results.columns:\n",
    "    raise KeyError(\"rob_label niet gevonden in resultaten.\")\n",
    "df_results['rob_label'] = df_results['rob_label'].astype(str).str.strip().str.lower()\n",
    "\n",
    "# 5) Titel beschikbaar maken in errors-tabel (optioneel)\n",
    "title_col = None\n",
    "for cand in ['title', 'Title', 'titel']:\n",
    "    if cand in df_results.columns:\n",
    "        title_col = cand\n",
    "        break\n",
    "\n",
    "# 6) Merge op id\n",
    "keep_cols = ['id', 'rob_label'] + ([title_col] if title_col else [])\n",
    "dfm = pd.merge(\n",
    "    df_h[['Artikel','Human_Label']],\n",
    "    df_results[keep_cols],\n",
    "    left_on='Artikel', right_on='id', how='inner'\n",
    ")\n",
    "\n",
    "# 7) Evaluatie\n",
    "y_true = dfm['Human_Label']\n",
    "y_pred = dfm['rob_label']\n",
    "\n",
    "labels_order = ['positief','negatief']\n",
    "print(\"\\n=== RobBERT (binaire evaluatie) ===\")\n",
    "print(classification_report(\n",
    "    y_true, y_pred,\n",
    "    labels=labels_order,\n",
    "    target_names=labels_order,\n",
    "    digits=3\n",
    "))\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred, labels=labels_order)\n",
    "cm_df = pd.DataFrame(\n",
    "    cm,\n",
    "    index=[f\"True {l}\" for l in labels_order],\n",
    "    columns=[f\"Pred {l}\" for l in labels_order]\n",
    ")\n",
    "print(\"Confusion matrix:\")\n",
    "print(cm_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c9e2095b-fb45-4d10-a6e0-8216e93efa7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Mismatches</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_2bbf7 th {\n",
       "  text-align: left;\n",
       "  vertical-align: top;\n",
       "}\n",
       "#T_2bbf7  td {\n",
       "  text-align: left;\n",
       "  vertical-align: top;\n",
       "}\n",
       "#T_2bbf7 table {\n",
       "  table-layout: fixed;\n",
       "  width: 100%;\n",
       "}\n",
       "#T_2bbf7 th.col0 {\n",
       "  width: 60px;\n",
       "}\n",
       "#T_2bbf7  td.col0 {\n",
       "  width: 60px;\n",
       "}\n",
       "#T_2bbf7 th.col1 {\n",
       "  width: 480px;\n",
       "}\n",
       "#T_2bbf7  td.col1 {\n",
       "  width: 480px;\n",
       "}\n",
       "#T_2bbf7 th.col2 {\n",
       "  width: 110px;\n",
       "}\n",
       "#T_2bbf7  td.col2 {\n",
       "  width: 110px;\n",
       "}\n",
       "#T_2bbf7 th.col3 {\n",
       "  width: 110px;\n",
       "}\n",
       "#T_2bbf7  td.col3 {\n",
       "  width: 110px;\n",
       "}\n",
       "#T_2bbf7_row0_col0, #T_2bbf7_row0_col1, #T_2bbf7_row0_col2, #T_2bbf7_row0_col3, #T_2bbf7_row1_col0, #T_2bbf7_row1_col1, #T_2bbf7_row1_col2, #T_2bbf7_row1_col3, #T_2bbf7_row2_col0, #T_2bbf7_row2_col1, #T_2bbf7_row2_col2, #T_2bbf7_row2_col3, #T_2bbf7_row3_col0, #T_2bbf7_row3_col1, #T_2bbf7_row3_col2, #T_2bbf7_row3_col3, #T_2bbf7_row4_col0, #T_2bbf7_row4_col1, #T_2bbf7_row4_col2, #T_2bbf7_row4_col3, #T_2bbf7_row5_col0, #T_2bbf7_row5_col1, #T_2bbf7_row5_col2, #T_2bbf7_row5_col3, #T_2bbf7_row6_col0, #T_2bbf7_row6_col1, #T_2bbf7_row6_col2, #T_2bbf7_row6_col3, #T_2bbf7_row7_col0, #T_2bbf7_row7_col1, #T_2bbf7_row7_col2, #T_2bbf7_row7_col3, #T_2bbf7_row8_col0, #T_2bbf7_row8_col1, #T_2bbf7_row8_col2, #T_2bbf7_row8_col3, #T_2bbf7_row9_col0, #T_2bbf7_row9_col1, #T_2bbf7_row9_col2, #T_2bbf7_row9_col3, #T_2bbf7_row10_col0, #T_2bbf7_row10_col1, #T_2bbf7_row10_col2, #T_2bbf7_row10_col3, #T_2bbf7_row11_col0, #T_2bbf7_row11_col1, #T_2bbf7_row11_col2, #T_2bbf7_row11_col3, #T_2bbf7_row12_col0, #T_2bbf7_row12_col1, #T_2bbf7_row12_col2, #T_2bbf7_row12_col3, #T_2bbf7_row13_col0, #T_2bbf7_row13_col1, #T_2bbf7_row13_col2, #T_2bbf7_row13_col3, #T_2bbf7_row14_col0, #T_2bbf7_row14_col1, #T_2bbf7_row14_col2, #T_2bbf7_row14_col3, #T_2bbf7_row15_col0, #T_2bbf7_row15_col1, #T_2bbf7_row15_col2, #T_2bbf7_row15_col3, #T_2bbf7_row16_col0, #T_2bbf7_row16_col1, #T_2bbf7_row16_col2, #T_2bbf7_row16_col3 {\n",
       "  white-space: normal;\n",
       "  vertical-align: top;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_2bbf7\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_2bbf7_level0_col0\" class=\"col_heading level0 col0\" >id</th>\n",
       "      <th id=\"T_2bbf7_level0_col1\" class=\"col_heading level0 col1\" >title</th>\n",
       "      <th id=\"T_2bbf7_level0_col2\" class=\"col_heading level0 col2\" >rob_label</th>\n",
       "      <th id=\"T_2bbf7_level0_col3\" class=\"col_heading level0 col3\" >Human_Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_2bbf7_row0_col0\" class=\"data row0 col0\" >7</td>\n",
       "      <td id=\"T_2bbf7_row0_col1\" class=\"data row0 col1\" >Nederlandse patiënt wacht te lang op betere medicijnen tegen kanker</td>\n",
       "      <td id=\"T_2bbf7_row0_col2\" class=\"data row0 col2\" >negatief</td>\n",
       "      <td id=\"T_2bbf7_row0_col3\" class=\"data row0 col3\" >positief</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_2bbf7_row1_col0\" class=\"data row1 col0\" >16</td>\n",
       "      <td id=\"T_2bbf7_row1_col1\" class=\"data row1 col1\" >'Ik vind het erg als 'n infuus van 25.000 euro wordt weggegooid'</td>\n",
       "      <td id=\"T_2bbf7_row1_col2\" class=\"data row1 col2\" >negatief</td>\n",
       "      <td id=\"T_2bbf7_row1_col3\" class=\"data row1 col3\" >positief</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_2bbf7_row2_col0\" class=\"data row2 col0\" >63</td>\n",
       "      <td id=\"T_2bbf7_row2_col1\" class=\"data row2 col1\" > Langer lijden of waardig sterven?</td>\n",
       "      <td id=\"T_2bbf7_row2_col2\" class=\"data row2 col2\" >positief</td>\n",
       "      <td id=\"T_2bbf7_row2_col3\" class=\"data row2 col3\" >negatief</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_2bbf7_row3_col0\" class=\"data row3 col0\" >66</td>\n",
       "      <td id=\"T_2bbf7_row3_col1\" class=\"data row3 col1\" >'Mijn belangrijkste vraag: wat wil je echt?'</td>\n",
       "      <td id=\"T_2bbf7_row3_col2\" class=\"data row3 col2\" >positief</td>\n",
       "      <td id=\"T_2bbf7_row3_col3\" class=\"data row3 col3\" >negatief</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_2bbf7_row4_col0\" class=\"data row4 col0\" >69</td>\n",
       "      <td id=\"T_2bbf7_row4_col1\" class=\"data row4 col1\" >Geef nieuwe medicijnen geen groen licht, maar oranje</td>\n",
       "      <td id=\"T_2bbf7_row4_col2\" class=\"data row4 col2\" >positief</td>\n",
       "      <td id=\"T_2bbf7_row4_col3\" class=\"data row4 col3\" >negatief</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_2bbf7_row5_col0\" class=\"data row5 col0\" >74</td>\n",
       "      <td id=\"T_2bbf7_row5_col1\" class=\"data row5 col1\" >Goed dat grens wordt gesteld aan uitdijen basispakket</td>\n",
       "      <td id=\"T_2bbf7_row5_col2\" class=\"data row5 col2\" >positief</td>\n",
       "      <td id=\"T_2bbf7_row5_col3\" class=\"data row5 col3\" >negatief</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_2bbf7_row6_col0\" class=\"data row6 col0\" >86</td>\n",
       "      <td id=\"T_2bbf7_row6_col1\" class=\"data row6 col1\" >Lat omhoog bij nieuwe kankermedicijnen</td>\n",
       "      <td id=\"T_2bbf7_row6_col2\" class=\"data row6 col2\" >positief</td>\n",
       "      <td id=\"T_2bbf7_row6_col3\" class=\"data row6 col3\" >negatief</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_2bbf7_row7_col0\" class=\"data row7 col0\" >94</td>\n",
       "      <td id=\"T_2bbf7_row7_col1\" class=\"data row7 col1\" >Toezichthouder moet strenger omgaan met kankermedicijnen die valse hoop geven</td>\n",
       "      <td id=\"T_2bbf7_row7_col2\" class=\"data row7 col2\" >positief</td>\n",
       "      <td id=\"T_2bbf7_row7_col3\" class=\"data row7 col3\" >negatief</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_2bbf7_row8_col0\" class=\"data row8 col0\" >99</td>\n",
       "      <td id=\"T_2bbf7_row8_col1\" class=\"data row8 col1\" >Harde keuzes zijn nodig in de zorg voordat nog meer mensen de dupe worden</td>\n",
       "      <td id=\"T_2bbf7_row8_col2\" class=\"data row8 col2\" >positief</td>\n",
       "      <td id=\"T_2bbf7_row8_col3\" class=\"data row8 col3\" >negatief</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_2bbf7_row9_col0\" class=\"data row9 col0\" >120</td>\n",
       "      <td id=\"T_2bbf7_row9_col1\" class=\"data row9 col1\" >Zijn die betere kankermedicijnen al dat geld waard? Kankerpatiënten leven langer met nieuwe medicijnen, het debat over de kosten laait op</td>\n",
       "      <td id=\"T_2bbf7_row9_col2\" class=\"data row9 col2\" >positief</td>\n",
       "      <td id=\"T_2bbf7_row9_col3\" class=\"data row9 col3\" >negatief</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_2bbf7_row10_col0\" class=\"data row10 col0\" >157</td>\n",
       "      <td id=\"T_2bbf7_row10_col1\" class=\"data row10 col1\" >'Geld is een perverse prikkel'</td>\n",
       "      <td id=\"T_2bbf7_row10_col2\" class=\"data row10 col2\" >positief</td>\n",
       "      <td id=\"T_2bbf7_row10_col3\" class=\"data row10 col3\" >negatief</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_2bbf7_row11_col0\" class=\"data row11 col0\" >181</td>\n",
       "      <td id=\"T_2bbf7_row11_col1\" class=\"data row11 col1\" >'Ik wilde geen Albert Schweitzer zijn'</td>\n",
       "      <td id=\"T_2bbf7_row11_col2\" class=\"data row11 col2\" >positief</td>\n",
       "      <td id=\"T_2bbf7_row11_col3\" class=\"data row11 col3\" >negatief</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_2bbf7_row12_col0\" class=\"data row12 col0\" >182</td>\n",
       "      <td id=\"T_2bbf7_row12_col1\" class=\"data row12 col1\" >Soms loont even afwachten bij kanker</td>\n",
       "      <td id=\"T_2bbf7_row12_col2\" class=\"data row12 col2\" >negatief</td>\n",
       "      <td id=\"T_2bbf7_row12_col3\" class=\"data row12 col3\" >positief</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_2bbf7_row13_col0\" class=\"data row13 col0\" >230</td>\n",
       "      <td id=\"T_2bbf7_row13_col1\" class=\"data row13 col1\" >Immuuntherapie vóór operatie uitgezaaide huidkanker biedt veelbelovende resultaten</td>\n",
       "      <td id=\"T_2bbf7_row13_col2\" class=\"data row13 col2\" >negatief</td>\n",
       "      <td id=\"T_2bbf7_row13_col3\" class=\"data row13 col3\" >positief</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_2bbf7_row14_col0\" class=\"data row14 col0\" >248</td>\n",
       "      <td id=\"T_2bbf7_row14_col1\" class=\"data row14 col1\" >Kunnen we onze medicijnen wel vertrouwen?</td>\n",
       "      <td id=\"T_2bbf7_row14_col2\" class=\"data row14 col2\" >positief</td>\n",
       "      <td id=\"T_2bbf7_row14_col3\" class=\"data row14 col3\" >negatief</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_2bbf7_row15_col0\" class=\"data row15 col0\" >255</td>\n",
       "      <td id=\"T_2bbf7_row15_col1\" class=\"data row15 col1\" >Uitzaaiende tumoren kapen hun hele omgeving; Een tumor is een complex mini-orgaantje dat zichzelf op ingenieuze wijze uitzaait</td>\n",
       "      <td id=\"T_2bbf7_row15_col2\" class=\"data row15 col2\" >positief</td>\n",
       "      <td id=\"T_2bbf7_row15_col3\" class=\"data row15 col3\" >negatief</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_2bbf7_row16_col0\" class=\"data row16 col0\" >271</td>\n",
       "      <td id=\"T_2bbf7_row16_col1\" class=\"data row16 col1\" >Beschikbaarheid van dure, levensreddende medicatie is in gevaar</td>\n",
       "      <td id=\"T_2bbf7_row16_col2\" class=\"data row16 col2\" >negatief</td>\n",
       "      <td id=\"T_2bbf7_row16_col3\" class=\"data row16 col3\" >positief</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1bde44fc760>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 8) Mismatches tonen (mooie HTML-tabel met wrapping)\n",
    "\n",
    "\n",
    "errors = dfm[dfm['Human_Label'] != dfm['rob_label']]\n",
    "\n",
    "cols = ['id', 'rob_label', 'Human_Label']\n",
    "if title_col:\n",
    "    cols.insert(1, title_col)\n",
    "\n",
    "styled = (\n",
    "    errors[cols]\n",
    "    .style\n",
    "    .set_properties(**{\n",
    "        'white-space': 'normal',     # laat tekst afbreken i.p.v. op één regel\n",
    "        'vertical-align': 'top'\n",
    "    })\n",
    "    .set_table_styles([\n",
    "        {'selector': 'th, td', 'props': [('text-align', 'left'), ('vertical-align', 'top')]},\n",
    "        {'selector': 'table', 'props': [('table-layout', 'fixed'), ('width', '100%')]},\n",
    "        # vaste kolombreedtes (pas aan naar wens)\n",
    "        {'selector': 'th.col0, td.col0', 'props': [('width', '60px')]},    # id\n",
    "        {'selector': 'th.col1, td.col1', 'props': [('width', '480px')]},   # title\n",
    "        {'selector': 'th.col2, td.col2', 'props': [('width', '110px')]},   # rob_label\n",
    "        {'selector': 'th.col3, td.col3', 'props': [('width', '110px')]}    # Human_Label\n",
    "    ])\n",
    "    .hide(axis=\"index\")\n",
    ")\n",
    "\n",
    "display(HTML(\"<h4>Mismatches</h4>\"))\n",
    "display(styled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075bfe8e-1b8b-43dc-9825-155255dc4b55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
