{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b230ab55-25f7-4a96-aa38-7db322d4d02c",
   "metadata": {},
   "source": [
    "# Zero-Shot NLI Sentiment (Dutch) Newspapers\n",
    "\n",
    "Dit notebook doet zero shot natural language inference om het sentiment van de geïncludeerde artikelen te classificeren in **positief** en **negatief**.\n",
    "\n",
    "De volgende modellen zijn getest, de eerste 3 zijn gefinetuned op nederlands en de laatste is multilangual:\n",
    "- `LoicDL/bert-base-dutch-cased-finetuned-snli`\n",
    "- `LoicDL/robbert-v2-dutch-finetuned-snli`\n",
    "- `loicDL/robbertje-dutch-finetuned-snli`\n",
    "- `MoritzLaurer/mDeBERTa-v3-base-mnli-xnli`\n",
    "\n",
    "Output: per artikel het voorspelde label en per klasse waarschijnlijkheidssscores (positief/negatief)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e65f00e-94ba-4d94-8fe5-ee39d0c471e5",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c659694-d732-4497-a0f4-5234a61594f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\semde\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] Kan opgegeven procedure niet vinden'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import os, re, json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "from ftfy import fix_text as _ftfy_fix\n",
    "import unicodedata\n",
    "import torch\n",
    "from transformers import pipeline, AutoTokenizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f44312-8960-40af-a87c-c93b90d1fede",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55c80969-fb19-4600-b58e-20eb927f1152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output-bestand\n",
    "OUT_CSV = \"out/nli_results.csv\"\n",
    "\n",
    "# NLI-modellen\n",
    "NLI_MODELS = [\n",
    "    \"LoicDL/bert-base-dutch-cased-finetuned-snli\", \n",
    "    \"LoicDL/robbert-v2-dutch-finetuned-snli\",\n",
    "    \"loicDL/robbertje-dutch-finetuned-snli\",\n",
    "    \"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\",\n",
    "]\n",
    "\n",
    "# Zero-shot labels & template (binary)\n",
    "ZS_LABELS = [\"positief\", \"negatief\"]\n",
    "HYPOTHESIS_TEMPLATE = \"Deze tekst is {}.\" # dit is de hypothese waarmee de NLI modellen gebruikt worden.\n",
    "\n",
    "# Sectie-gewichten (title=1, lead=1, body=1)\n",
    "TITLE_W = 1.0\n",
    "LEAD_W  = 1.0\n",
    "BODY_W  = 1.0  # (wordt intern gelijk verdeeld/gewogen over body-chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceaf87ed-7165-4a2e-92ca-7ca6c906193b",
   "metadata": {},
   "source": [
    "# Load Title Lead and Body Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "512e2f26-17fe-404a-83b7-8e349d730735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Inlezen uit Title_Lead_Body.xlsx ===\n",
    "XLSX_PATH = \"out/Title_Lead_Body.xlsx\"\n",
    "\n",
    "df_input = pd.read_excel(XLSX_PATH)\n",
    "# kolomnamen naar lower\n",
    "df_input = df_input.rename(columns={c: c.lower() for c in df_input.columns})\n",
    "# vereiste kolommen\n",
    "need = {\"id\", \"title\", \"lead\", \"body\"}\n",
    "missing = need - set(df_input.columns)\n",
    "if missing:\n",
    "    raise ValueError(f\"Ontbrekende kolommen in {XLSX_PATH}: {missing}\")\n",
    "\n",
    "df_input[\"id\"] = df_input[\"id\"].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1eeda73-fe11-46ea-85c9-902441f6997a",
   "metadata": {},
   "source": [
    "# Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e01668f0-9fbd-42ce-b0b8-3fccb933ff8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Device set to use cpu\n",
      "Device set to use cpu\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['LoicDL/bert-base-dutch-cased-finetuned-snli',\n",
       " 'LoicDL/robbert-v2-dutch-finetuned-snli',\n",
       " 'loicDL/robbertje-dutch-finetuned-snli',\n",
       " 'MoritzLaurer/mDeBERTa-v3-base-mnli-xnli']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Pipelines en tokenizer klaarzetten ===\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "\n",
    "# Tokenizer voor chunken: hierbij gebruik ik de MoritzLaurer-tokenizer (stabiel en multilingual)\n",
    "chunk_tokenizer = AutoTokenizer.from_pretrained(\"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\")\n",
    "\n",
    "# Zero-shot pipelines voor alle modellen\n",
    "pipelines = {\n",
    "    mid: pipeline(\"zero-shot-classification\", model=mid, tokenizer=mid, device=device)\n",
    "    for mid in NLI_MODELS\n",
    "}\n",
    "list(pipelines.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438d578a-deb7-4df5-b7a8-c91a6e3c6700",
   "metadata": {},
   "source": [
    "# Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bbbe33ff-709c-4b8a-af54-b728a584118e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Body chunken (token-gebonden, met stride) ===\n",
    "def chunk_body(\n",
    "    text: str,\n",
    "    tokenizer,\n",
    "    *,\n",
    "    max_tokens: int = 400,\n",
    "    stride: int = 50,\n",
    "    prefer_paragraphs: bool = True,\n",
    "    reserve_for_hypothesis: int = 48,   # marge voor [CLS]/[SEP] + hypothesis tokens\n",
    ") -> List[str]:\n",
    "    text = (text or \"\").strip()\n",
    "    if not text:\n",
    "        return []\n",
    "\n",
    "    # Model max length (veiligheidsmarge)\n",
    "    try:\n",
    "        model_max = int(getattr(tokenizer.model_max_length, \"__int__\", lambda: 512)())\n",
    "    except Exception:\n",
    "        model_max = 512\n",
    "\n",
    "    eff_max = max(16, min(max_tokens, model_max - max(0, reserve_for_hypothesis)))\n",
    "\n",
    "    def _chunk_ids(ids: List[int]) -> List[str]:\n",
    "        if len(ids) <= eff_max:\n",
    "            s = tokenizer.decode(ids, clean_up_tokenization_spaces=True, skip_special_tokens=True).strip()\n",
    "            return [s] if s else []\n",
    "        chunks = []\n",
    "        i, L = 0, len(ids)\n",
    "        step = max(1, eff_max - stride)\n",
    "        while i < L:\n",
    "            j = min(i + eff_max, L)\n",
    "            window = ids[i:j]\n",
    "            if window:\n",
    "                s = tokenizer.decode(window, clean_up_tokenization_spaces=True, skip_special_tokens=True).strip()\n",
    "                if s:\n",
    "                    chunks.append(s)\n",
    "            if j >= L:\n",
    "                break\n",
    "            i += step\n",
    "        return chunks\n",
    "\n",
    "    out: List[str] = []\n",
    "    if prefer_paragraphs:\n",
    "        paras = [p.strip() for p in re.split(r\"\\n\\s*\\n\", text) if p.strip()]\n",
    "        for p in paras:\n",
    "            ids = tokenizer.encode(p, add_special_tokens=False)\n",
    "            out.extend(_chunk_ids(ids))\n",
    "    else:\n",
    "        ids = tokenizer.encode(text, add_special_tokens=False)\n",
    "        out.extend(_chunk_ids(ids))\n",
    "\n",
    "    return [c for c in out if c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46f6d6a4-a33b-46c6-991c-c5ea7d82467b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === NLI-score voor één tekst (binaire probs, renormalized) ===\n",
    "def nli_score_text_bin_single(text: str, *, clf) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Geeft (p_pos, p_neg) terug op basis van zero-shot NLI met je template.\n",
    "    \"\"\"\n",
    "    txt = (text or \"\").strip()\n",
    "    if not txt:\n",
    "        return 0.5, 0.5\n",
    "\n",
    "    out = clf(\n",
    "        txt,\n",
    "        ZS_LABELS,\n",
    "        multi_label=False,\n",
    "        hypothesis_template=HYPOTHESIS_TEMPLATE,\n",
    "    )\n",
    "    # out['labels'] zijn candidate_labels in score-volgorde\n",
    "    scores = {str(lbl).lower(): float(scr) for lbl, scr in zip(out[\"labels\"], out[\"scores\"])}\n",
    "    p_pos = scores.get(\"positief\", 0.0)\n",
    "    p_neg = scores.get(\"negatief\", 0.0)\n",
    "\n",
    "    s = p_pos + p_neg\n",
    "    if s <= 0:\n",
    "        return 0.5, 0.5\n",
    "    return p_pos / s, p_neg / s\n",
    "\n",
    "\n",
    "# === Aggregatie over title/lead/body met gewenste weging ===\n",
    "def classify_title_lead_body_bin(\n",
    "    title: str,\n",
    "    lead: str,\n",
    "    body: str,\n",
    "    *,\n",
    "    clf,                  # zero-shot pipeline\n",
    "    tokenizer,            # voor chunking\n",
    "    max_tokens: int = 400,\n",
    "    stride: int = 50,\n",
    "    debug: bool = False,\n",
    ") -> Tuple[str, Dict[str, float]]:\n",
    "    # Title\n",
    "    t_pos, t_neg = nli_score_text_bin_single(title, clf=clf) if (title or \"\").strip() else (0.5, 0.5)\n",
    "    if debug:\n",
    "        print(f\"[DBG] title: p_pos={t_pos:.4f} p_neg={t_neg:.4f}\")\n",
    "\n",
    "    # Lead\n",
    "    l_pos, l_neg = nli_score_text_bin_single(lead, clf=clf) if (lead or \"\").strip() else (0.5, 0.5)\n",
    "    if debug:\n",
    "        print(f\"[DBG] lead : p_pos={l_pos:.4f} p_neg={l_neg:.4f}\")\n",
    "\n",
    "    # Body → chunks → gewogen gemiddelde waarbij som(chunk-gewichten)=1\n",
    "    b_pos = b_neg = 0.5\n",
    "    chunks = chunk_body(\n",
    "        body,\n",
    "        tokenizer,\n",
    "        max_tokens=max_tokens,\n",
    "        stride=stride,\n",
    "        prefer_paragraphs=True\n",
    "    )\n",
    "    if chunks:\n",
    "        # weeg chunks naar lengte (tokens) en NORMALISEER naar som=1\n",
    "        tok_lens = [len(tokenizer.encode(c, add_special_tokens=False)) for c in chunks]\n",
    "        total = sum(tok_lens)\n",
    "        if total <= 0:\n",
    "            weights = [1.0 / len(chunks)] * len(chunks)\n",
    "        else:\n",
    "            weights = [tl / total for tl in tok_lens]\n",
    "\n",
    "        b_pos = 0.0\n",
    "        b_neg = 0.0\n",
    "        for w, c in zip(weights, chunks):\n",
    "            ppos, pneg = nli_score_text_bin_single(c, clf=clf)\n",
    "            b_pos += w * ppos\n",
    "            b_neg += w * pneg\n",
    "        if debug:\n",
    "            print(f\"[DBG] body : chunks={len(chunks)} p_pos={b_pos:.4f} p_neg={b_neg:.4f}\")\n",
    "\n",
    "    # Sectie-gewichten: title=1, lead=1, body=1\n",
    "    pos_total = TITLE_W * t_pos + LEAD_W * l_pos + BODY_W * b_pos\n",
    "    neg_total = TITLE_W * t_neg + LEAD_W * l_neg + BODY_W * b_neg\n",
    "\n",
    "    denom = pos_total + neg_total\n",
    "    if denom <= 0:\n",
    "        p_pos_final = p_neg_final = 0.5\n",
    "    else:\n",
    "        p_pos_final = pos_total / denom\n",
    "        p_neg_final = neg_total / denom\n",
    "\n",
    "    label = \"positief\" if p_pos_final >= p_neg_final else \"negatief\"\n",
    "    return label, {\"positief\": float(p_pos_final), \"negatief\": float(p_neg_final)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf9801e-c6c3-48c6-adb5-2e713a681642",
   "metadata": {},
   "source": [
    "# NLI Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3f58865-80d8-4012-a43a-c0b634a70408",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NLI:   0%|                                                                                      | 0/70 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (861 > 512). Running this sequence through the model will result in indexing errors\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "NLI: 100%|██████████████████████████████████████████████████████████████████████████| 70/70 [2:13:06<00:00, 114.09s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>lead</th>\n",
       "      <th>bert_base_dutch_cased_finetuned_snli_label</th>\n",
       "      <th>bert_base_dutch_cased_finetuned_snli_positief</th>\n",
       "      <th>bert_base_dutch_cased_finetuned_snli_negatief</th>\n",
       "      <th>robbert_v2_dutch_finetuned_snli_label</th>\n",
       "      <th>robbert_v2_dutch_finetuned_snli_positief</th>\n",
       "      <th>robbert_v2_dutch_finetuned_snli_negatief</th>\n",
       "      <th>robbertje_dutch_finetuned_snli_label</th>\n",
       "      <th>robbertje_dutch_finetuned_snli_positief</th>\n",
       "      <th>robbertje_dutch_finetuned_snli_negatief</th>\n",
       "      <th>mDeBERTa_v3_base_mnli_xnli_label</th>\n",
       "      <th>mDeBERTa_v3_base_mnli_xnli_positief</th>\n",
       "      <th>mDeBERTa_v3_base_mnli_xnli_negatief</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>Nederlandse patiënt wacht te lang op betere me...</td>\n",
       "      <td>Wat een prachtig bericht onlangs, dat meer kan...</td>\n",
       "      <td>positief</td>\n",
       "      <td>0.681403</td>\n",
       "      <td>0.318597</td>\n",
       "      <td>positief</td>\n",
       "      <td>0.561398</td>\n",
       "      <td>0.438602</td>\n",
       "      <td>negatief</td>\n",
       "      <td>0.485963</td>\n",
       "      <td>0.514037</td>\n",
       "      <td>positief</td>\n",
       "      <td>0.659065</td>\n",
       "      <td>0.340935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>Nieuwe kankermedicijnen leveren meer financiël...</td>\n",
       "      <td>Vorige week verscheen in Trouw een artikel met...</td>\n",
       "      <td>positief</td>\n",
       "      <td>0.647363</td>\n",
       "      <td>0.352637</td>\n",
       "      <td>positief</td>\n",
       "      <td>0.592988</td>\n",
       "      <td>0.407012</td>\n",
       "      <td>positief</td>\n",
       "      <td>0.522930</td>\n",
       "      <td>0.477070</td>\n",
       "      <td>negatief</td>\n",
       "      <td>0.436804</td>\n",
       "      <td>0.563196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>Hoe controleer je verstopte moedervlekken?</td>\n",
       "      <td>Meer dan twintig jaar geleden ontdekte ze op h...</td>\n",
       "      <td>positief</td>\n",
       "      <td>0.646949</td>\n",
       "      <td>0.353051</td>\n",
       "      <td>positief</td>\n",
       "      <td>0.551829</td>\n",
       "      <td>0.448171</td>\n",
       "      <td>negatief</td>\n",
       "      <td>0.339010</td>\n",
       "      <td>0.660990</td>\n",
       "      <td>negatief</td>\n",
       "      <td>0.466271</td>\n",
       "      <td>0.533729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>'Ik vind het erg als 'n infuus van 25.000 euro...</td>\n",
       "      <td>Waarom schrijven artsen 1005 milligram van een...</td>\n",
       "      <td>positief</td>\n",
       "      <td>0.644479</td>\n",
       "      <td>0.355521</td>\n",
       "      <td>positief</td>\n",
       "      <td>0.524401</td>\n",
       "      <td>0.475599</td>\n",
       "      <td>negatief</td>\n",
       "      <td>0.429237</td>\n",
       "      <td>0.570763</td>\n",
       "      <td>negatief</td>\n",
       "      <td>0.320823</td>\n",
       "      <td>0.679177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21</td>\n",
       "      <td>Wachtlijsten en personeelstekort: het 'zorginf...</td>\n",
       "      <td>De gezondheidszorg is 'op', er zit geen rek me...</td>\n",
       "      <td>positief</td>\n",
       "      <td>0.623405</td>\n",
       "      <td>0.376595</td>\n",
       "      <td>positief</td>\n",
       "      <td>0.503445</td>\n",
       "      <td>0.496555</td>\n",
       "      <td>negatief</td>\n",
       "      <td>0.439364</td>\n",
       "      <td>0.560636</td>\n",
       "      <td>negatief</td>\n",
       "      <td>0.402679</td>\n",
       "      <td>0.597321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title  \\\n",
       "0   7  Nederlandse patiënt wacht te lang op betere me...   \n",
       "1  10  Nieuwe kankermedicijnen leveren meer financiël...   \n",
       "2  11         Hoe controleer je verstopte moedervlekken?   \n",
       "3  16  'Ik vind het erg als 'n infuus van 25.000 euro...   \n",
       "4  21  Wachtlijsten en personeelstekort: het 'zorginf...   \n",
       "\n",
       "                                                lead  \\\n",
       "0  Wat een prachtig bericht onlangs, dat meer kan...   \n",
       "1  Vorige week verscheen in Trouw een artikel met...   \n",
       "2  Meer dan twintig jaar geleden ontdekte ze op h...   \n",
       "3  Waarom schrijven artsen 1005 milligram van een...   \n",
       "4  De gezondheidszorg is 'op', er zit geen rek me...   \n",
       "\n",
       "  bert_base_dutch_cased_finetuned_snli_label  \\\n",
       "0                                   positief   \n",
       "1                                   positief   \n",
       "2                                   positief   \n",
       "3                                   positief   \n",
       "4                                   positief   \n",
       "\n",
       "   bert_base_dutch_cased_finetuned_snli_positief  \\\n",
       "0                                       0.681403   \n",
       "1                                       0.647363   \n",
       "2                                       0.646949   \n",
       "3                                       0.644479   \n",
       "4                                       0.623405   \n",
       "\n",
       "   bert_base_dutch_cased_finetuned_snli_negatief  \\\n",
       "0                                       0.318597   \n",
       "1                                       0.352637   \n",
       "2                                       0.353051   \n",
       "3                                       0.355521   \n",
       "4                                       0.376595   \n",
       "\n",
       "  robbert_v2_dutch_finetuned_snli_label  \\\n",
       "0                              positief   \n",
       "1                              positief   \n",
       "2                              positief   \n",
       "3                              positief   \n",
       "4                              positief   \n",
       "\n",
       "   robbert_v2_dutch_finetuned_snli_positief  \\\n",
       "0                                  0.561398   \n",
       "1                                  0.592988   \n",
       "2                                  0.551829   \n",
       "3                                  0.524401   \n",
       "4                                  0.503445   \n",
       "\n",
       "   robbert_v2_dutch_finetuned_snli_negatief  \\\n",
       "0                                  0.438602   \n",
       "1                                  0.407012   \n",
       "2                                  0.448171   \n",
       "3                                  0.475599   \n",
       "4                                  0.496555   \n",
       "\n",
       "  robbertje_dutch_finetuned_snli_label  \\\n",
       "0                             negatief   \n",
       "1                             positief   \n",
       "2                             negatief   \n",
       "3                             negatief   \n",
       "4                             negatief   \n",
       "\n",
       "   robbertje_dutch_finetuned_snli_positief  \\\n",
       "0                                 0.485963   \n",
       "1                                 0.522930   \n",
       "2                                 0.339010   \n",
       "3                                 0.429237   \n",
       "4                                 0.439364   \n",
       "\n",
       "   robbertje_dutch_finetuned_snli_negatief mDeBERTa_v3_base_mnli_xnli_label  \\\n",
       "0                                 0.514037                         positief   \n",
       "1                                 0.477070                         negatief   \n",
       "2                                 0.660990                         negatief   \n",
       "3                                 0.570763                         negatief   \n",
       "4                                 0.560636                         negatief   \n",
       "\n",
       "   mDeBERTa_v3_base_mnli_xnli_positief  mDeBERTa_v3_base_mnli_xnli_negatief  \n",
       "0                             0.659065                             0.340935  \n",
       "1                             0.436804                             0.563196  \n",
       "2                             0.466271                             0.533729  \n",
       "3                             0.320823                             0.679177  \n",
       "4                             0.402679                             0.597321  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = []\n",
    "for _, r in tqdm(df_input.iterrows(), total=len(df_input), desc=\"NLI\"):\n",
    "    rec = {\n",
    "        \"id\": int(r[\"id\"]),\n",
    "        \"title\": r[\"title\"],\n",
    "        \"lead\": r[\"lead\"],\n",
    "    }\n",
    "    title = r[\"title\"]\n",
    "    lead  = r[\"lead\"]\n",
    "    body  = r[\"body\"]\n",
    "\n",
    "    for mid, clf in pipelines.items():\n",
    "        label, scores = classify_title_lead_body_bin(\n",
    "            title, lead, body,\n",
    "            clf=clf,\n",
    "            tokenizer=chunk_tokenizer,\n",
    "            max_tokens=300,   # kan 400; 300 = iets sneller, vaak voldoende\n",
    "            stride=50,\n",
    "            debug=False\n",
    "        )\n",
    "        key = mid.split(\"/\")[-1].replace(\"-\", \"_\")\n",
    "        rec[f\"{key}_label\"]     = label\n",
    "        rec[f\"{key}_positief\"]  = float(scores[\"positief\"])\n",
    "        rec[f\"{key}_negatief\"]  = float(scores[\"negatief\"])\n",
    "    rows.append(rec)\n",
    "\n",
    "df_out = pd.DataFrame(rows).sort_values(\"id\")\n",
    "df_out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be1454c1-0817-40d7-a44d-8cb2c64df1b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DONE] Wrote binary results to out/nli_results.csv\n"
     ]
    }
   ],
   "source": [
    "df_out.to_csv(OUT_CSV, index=False)\n",
    "print(\"[DONE] Wrote binary results to out/nli_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1dbde03-4a9e-46be-8771-9c9a1ad4c2b9",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2feae59-6656-42bd-b7cf-59319c521102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  bert_base_dutch_cased_finetuned_snli_negatief  \\\n",
      "0   7                                          False   \n",
      "1  10                                          False   \n",
      "2  11                                          False   \n",
      "3  16                                          False   \n",
      "4  21                                          False   \n",
      "\n",
      "   bert_base_dutch_cased_finetuned_snli_positief  \\\n",
      "0                                           True   \n",
      "1                                           True   \n",
      "2                                           True   \n",
      "3                                           True   \n",
      "4                                           True   \n",
      "\n",
      "   robbert_v2_dutch_finetuned_snli_negatief  \\\n",
      "0                                     False   \n",
      "1                                     False   \n",
      "2                                     False   \n",
      "3                                     False   \n",
      "4                                     False   \n",
      "\n",
      "   robbert_v2_dutch_finetuned_snli_positief  \\\n",
      "0                                      True   \n",
      "1                                      True   \n",
      "2                                      True   \n",
      "3                                      True   \n",
      "4                                      True   \n",
      "\n",
      "   robbertje_dutch_finetuned_snli_negatief  \\\n",
      "0                                     True   \n",
      "1                                    False   \n",
      "2                                     True   \n",
      "3                                     True   \n",
      "4                                     True   \n",
      "\n",
      "   robbertje_dutch_finetuned_snli_positief  \\\n",
      "0                                    False   \n",
      "1                                     True   \n",
      "2                                    False   \n",
      "3                                    False   \n",
      "4                                    False   \n",
      "\n",
      "   mDeBERTa_v3_base_mnli_xnli_negatief  mDeBERTa_v3_base_mnli_xnli_positief  \n",
      "0                                False                                 True  \n",
      "1                                 True                                False  \n",
      "2                                 True                                False  \n",
      "3                                 True                                False  \n",
      "4                                 True                                False  \n",
      "\n",
      "Samenvatting aantallen per model:\n",
      "                                      positief  negatief\n",
      "Model                                                   \n",
      "bert_base_dutch_cased_finetuned_snli        69         1\n",
      "robbert_v2_dutch_finetuned_snli             63         7\n",
      "robbertje_dutch_finetuned_snli              28        42\n",
      "mDeBERTa_v3_base_mnli_xnli                  46        24\n"
     ]
    }
   ],
   "source": [
    "# === Load results (NLI models) ===\n",
    "\n",
    "# 1) Resultaten ophalen (in-memory heeft voorrang)\n",
    "df_results = None\n",
    "for varname in (\"df_out\", \"df\"):\n",
    "    if varname in globals():\n",
    "        df_results = globals()[varname].copy()\n",
    "        break\n",
    "\n",
    "# 2) Anders van schijf (xlsx > csv)\n",
    "if df_results is None:\n",
    "    candidates = [\n",
    "        \"out/nli_results.xlsx\",\n",
    "        \"nli_results.xlsx\",\n",
    "        \"out/nli_results.csv\",\n",
    "        \"nli_results.csv\",\n",
    "    ]\n",
    "    path = next((p for p in candidates if os.path.exists(p)), None)\n",
    "    if path is None:\n",
    "        raise FileNotFoundError(\"Kon geen nli_results-(xlsx/csv) vinden of in-memory df_out/df.\")\n",
    "    df_results = pd.read_excel(path) if path.endswith(\".xlsx\") else pd.read_csv(path)\n",
    "\n",
    "df = df_results.copy()\n",
    "\n",
    "# 3) Zorg voor nette integer 'id'\n",
    "def to_int_id(v):\n",
    "    try:\n",
    "        return int(v)\n",
    "    except Exception:\n",
    "        return pd.NA\n",
    "\n",
    "if \"id\" not in df.columns:\n",
    "    # Laatste vangnet: als er nog 'file' bestaat, probeer daaruit een cijfer te halen\n",
    "    if \"file\" in df.columns:\n",
    "        def extract_id_from_file(val):\n",
    "            s = str(val)\n",
    "            m = re.search(r\"(\\d+)\", s)\n",
    "            return int(m.group(1)) if m else pd.NA\n",
    "        df[\"id\"] = df[\"file\"].apply(extract_id_from_file)\n",
    "    else:\n",
    "        df[\"id\"] = np.arange(1, len(df) + 1)\n",
    "\n",
    "df[\"id\"] = df[\"id\"].apply(to_int_id)\n",
    "\n",
    "# 4) Vind *_label kolommen en normaliseer\n",
    "label_cols = [c for c in df.columns if c.endswith(\"_label\")]\n",
    "if not label_cols:\n",
    "    raise KeyError(\"Geen *_label kolommen gevonden in de NLI-resultaten.\")\n",
    "\n",
    "for c in label_cols:\n",
    "    df[c] = df[c].astype(str).str.strip().str.lower()\n",
    "\n",
    "# 5) One-hot per model, robuust (zorgt voor kolommen ..._positief en ..._negatief als aanwezig)\n",
    "one_hot_frames = []\n",
    "for c in label_cols:\n",
    "    model_prefix = c.replace(\"_label\", \"\")\n",
    "    # get_dummies (kan ontbreken als label niet voorkomt)\n",
    "    oh = pd.get_dummies(df[[c]].rename(columns={c: model_prefix}),\n",
    "                        columns=[model_prefix], prefix=model_prefix)\n",
    "    # Zorg dat de binaire kolommen bestaan (ook als niet gezien)\n",
    "    for lab in (\"positief\", \"negatief\"):\n",
    "        col = f\"{model_prefix}_{lab}\"\n",
    "        if col not in oh.columns:\n",
    "            oh[col] = 0\n",
    "    # Sorteer kolommen voor netheid\n",
    "    oh = oh.reindex(sorted(oh.columns), axis=1)\n",
    "    one_hot_frames.append(oh)\n",
    "\n",
    "df_onehot = pd.concat([df[[\"id\"]]] + one_hot_frames, axis=1)\n",
    "\n",
    "print(df_onehot.head())\n",
    "\n",
    "# 6) Samenvatting per model (positief/negatief)\n",
    "summary = {}\n",
    "for c in label_cols:\n",
    "    model_prefix = c.replace(\"_label\", \"\")\n",
    "    pos = int(df_onehot.filter(like=f\"{model_prefix}_positief\").sum().sum())\n",
    "    neg = int(df_onehot.filter(like=f\"{model_prefix}_negatief\").sum().sum())\n",
    "    summary[model_prefix] = {\"positief\": pos, \"negatief\": neg}\n",
    "\n",
    "summary_df = pd.DataFrame(summary).T.astype(int)\n",
    "summary_df.index.name = \"Model\"\n",
    "print(\"\\nSamenvatting aantallen per model:\")\n",
    "print(summary_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bc90f3b-a7f9-4202-9488-dfa421de363b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== bert_base_dutch_cased_finetuned_snli (Zero-Shot NLI, binary) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positief      0.625     1.000     0.769        40\n",
      "    negatief      1.000     0.040     0.077        25\n",
      "\n",
      "    accuracy                          0.631        65\n",
      "   macro avg      0.812     0.520     0.423        65\n",
      "weighted avg      0.769     0.631     0.503        65\n",
      "\n",
      "Confusion matrix:\n",
      "               Pred positief  Pred negatief\n",
      "True positief             40              0\n",
      "True negatief             24              1\n",
      "\n",
      "=== robbert_v2_dutch_finetuned_snli (Zero-Shot NLI, binary) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positief      0.655     0.950     0.776        40\n",
      "    negatief      0.714     0.200     0.312        25\n",
      "\n",
      "    accuracy                          0.662        65\n",
      "   macro avg      0.685     0.575     0.544        65\n",
      "weighted avg      0.678     0.662     0.597        65\n",
      "\n",
      "Confusion matrix:\n",
      "               Pred positief  Pred negatief\n",
      "True positief             38              2\n",
      "True negatief             20              5\n",
      "\n",
      "=== robbertje_dutch_finetuned_snli (Zero-Shot NLI, binary) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positief      0.720     0.450     0.554        40\n",
      "    negatief      0.450     0.720     0.554        25\n",
      "\n",
      "    accuracy                          0.554        65\n",
      "   macro avg      0.585     0.585     0.554        65\n",
      "weighted avg      0.616     0.554     0.554        65\n",
      "\n",
      "Confusion matrix:\n",
      "               Pred positief  Pred negatief\n",
      "True positief             18             22\n",
      "True negatief              7             18\n",
      "\n",
      "=== mDeBERTa_v3_base_mnli_xnli (Zero-Shot NLI, binary) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positief      0.814     0.875     0.843        40\n",
      "    negatief      0.773     0.680     0.723        25\n",
      "\n",
      "    accuracy                          0.800        65\n",
      "   macro avg      0.793     0.778     0.783        65\n",
      "weighted avg      0.798     0.800     0.797        65\n",
      "\n",
      "Confusion matrix:\n",
      "               Pred positief  Pred negatief\n",
      "True positief             35              5\n",
      "True negatief              8             17\n"
     ]
    }
   ],
   "source": [
    "# === Evaluatie: Human vs NLI (binair: positief/negatief) ===\n",
    "\n",
    "# 1) Pak dezelfde df_results als in de vorige cell\n",
    "try:\n",
    "    df_n = df_results.copy()\n",
    "except NameError:\n",
    "    # fallback: alsnog proberen te laden (zelfde logica)\n",
    "    import os\n",
    "    candidates = [\n",
    "        \"out/nli_results.xlsx\",\n",
    "        \"nli_results.xlsx\",\n",
    "        \"out/nli_results.csv\",\n",
    "        \"nli_results.csv\",\n",
    "    ]\n",
    "    path = next((p for p in candidates if os.path.exists(p)), None)\n",
    "    if path is None:\n",
    "        raise FileNotFoundError(\"Kon geen NLI-resultaten vinden voor evaluatie.\")\n",
    "    df_n = pd.read_excel(path) if path.endswith(\".xlsx\") else pd.read_csv(path)\n",
    "\n",
    "# 2) Human labels\n",
    "df_h = pd.read_excel(\"out/Human_Sentiment.xlsx\")  # verwacht: Artikel, Sentiment\n",
    "\n",
    "# 3) IDs netjes naar int\n",
    "def to_int_or_none(x):\n",
    "    try:\n",
    "        return int(x)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "if \"id\" not in df_n.columns:\n",
    "    raise KeyError(\"Resultaten missen een 'id' kolom.\")\n",
    "df_n[\"id\"] = df_n[\"id\"].apply(to_int_or_none)\n",
    "\n",
    "if not pd.api.types.is_integer_dtype(df_h[\"Artikel\"]):\n",
    "    df_h[\"Artikel\"] = df_h[\"Artikel\"].apply(to_int_or_none)\n",
    "\n",
    "# 4) Labels normaliseren + alleen pos/neg\n",
    "df_h[\"Human_Label\"] = df_h[\"Sentiment\"].astype(str).str.strip().str.lower()\n",
    "df_h = df_h[df_h[\"Human_Label\"].isin({\"positief\", \"negatief\"})].copy()\n",
    "\n",
    "# 5) Merge\n",
    "dfm = pd.merge(df_h[[\"Artikel\", \"Human_Label\"]],\n",
    "               df_n,\n",
    "               left_on=\"Artikel\", right_on=\"id\",\n",
    "               how=\"inner\")\n",
    "\n",
    "# 6) Vind alle *_label kolommen (per model)\n",
    "model_label_cols = [c for c in dfm.columns if c.endswith(\"_label\")]\n",
    "if not model_label_cols:\n",
    "    raise KeyError(\"Geen *_label kolommen gevonden in NLI-resultaten voor evaluatie.\")\n",
    "\n",
    "labels_order = [\"positief\", \"negatief\"]\n",
    "\n",
    "# 7) Evaluatie per model\n",
    "for col in model_label_cols:\n",
    "    model_name = col.replace(\"_label\", \"\")\n",
    "    y_true = dfm[\"Human_Label\"].astype(str).str.lower()\n",
    "    y_pred = dfm[col].astype(str).str.lower()\n",
    "\n",
    "    mask = y_true.isin(labels_order) & y_pred.isin(labels_order)\n",
    "    y_true_m = y_true[mask]\n",
    "    y_pred_m = y_pred[mask]\n",
    "\n",
    "    print(f\"\\n=== {model_name} (Zero-Shot NLI, binary) ===\")\n",
    "    print(classification_report(\n",
    "        y_true_m, y_pred_m,\n",
    "        labels=labels_order,\n",
    "        target_names=labels_order,\n",
    "        digits=3\n",
    "    ))\n",
    "\n",
    "    cm = confusion_matrix(y_true_m, y_pred_m, labels=labels_order)\n",
    "    cm_df = pd.DataFrame(\n",
    "        cm,\n",
    "        index=[f\"True {l}\" for l in labels_order],\n",
    "        columns=[f\"Pred {l}\" for l in labels_order]\n",
    "    )\n",
    "    print(\"Confusion matrix:\")\n",
    "    print(cm_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a490213f-575f-4b96-8d80-9662921d9dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = dfm[dfm['Human_Label'] != dfm['mDeBERTa_v3_base_mnli_xnli_label']]\n",
    "cols = ['id', 'title', 'mDeBERTa_v3_base_mnli_xnli_label', 'Human_Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de87a65a-7664-4c45-bf2b-09c1778de3ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    id                                              title  \\\n",
      "2   11         Hoe controleer je verstopte moedervlekken?   \n",
      "3   16  'Ik vind het erg als 'n infuus van 25.000 euro...   \n",
      "4   26  Tijd om te kiezen: dure behandelingen of voldo...   \n",
      "8   39                      Het dna van de tumor in kaart   \n",
      "13  66       'Mijn belangrijkste vraag: wat wil je echt?'   \n",
      "\n",
      "   mDeBERTa_v3_base_mnli_xnli_label Human_Label  \n",
      "2                          negatief    positief  \n",
      "3                          negatief    positief  \n",
      "4                          positief    negatief  \n",
      "8                          positief    negatief  \n",
      "13                         positief    negatief  \n"
     ]
    }
   ],
   "source": [
    "print(errors[cols].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b862d8-6b87-432d-94f1-c29ba13c4291",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
